{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Preparación de datos, generación de embeddings, indexación y almacenamiento en una base de datos vectorial\n",
    "\n",
    "Este script realiza las siguientes tareas:\n",
    "1. Carga y preprocesa los datos del dataset de tweets sobre clima.\n",
    "2. Genera embeddings utilizando un modelo pre-entrenado.\n",
    "3. Indexa y almacena los embeddings en una base de datos vectorial.\n",
    "4. Demuestra cómo realizar consultas básicas en la base de datos vectorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\OneDrive\\Desktop\\Universidad Semestre 9\\Almac y Recup de Info\\trabajo2\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import chromadb\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando y preprocesando datos...\n"
     ]
    }
   ],
   "source": [
    "# 1. Cargar y preprocesar los datos\n",
    "print(\"Cargando y preprocesando datos...\")\n",
    "df = pd.read_csv('./data/processed/processedClimateTwitterData.csv')\n",
    "texts = df['processed_text'].tolist()\n",
    "ids = df.index.astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\OneDrive\\Desktop\\Universidad Semestre 9\\Almac y Recup de Info\\trabajo2\\myenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\andre\\OneDrive\\Desktop\\Universidad Semestre 9\\Almac y Recup de Info\\trabajo2\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesados 0/72405 textos\n",
      "Procesados 8000/72405 textos\n",
      "Procesados 16000/72405 textos\n",
      "Procesados 24000/72405 textos\n",
      "Procesados 32000/72405 textos\n",
      "Procesados 40000/72405 textos\n",
      "Procesados 48000/72405 textos\n",
      "Procesados 56000/72405 textos\n",
      "Procesados 64000/72405 textos\n",
      "Procesados 72000/72405 textos\n"
     ]
    }
   ],
   "source": [
    "print(\"Generando embeddings...\")\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "def generate_embeddings_batch(texts, batch_size=64):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Procesados {i}/{len(texts)} textos\")\n",
    "    return embeddings\n",
    "\n",
    "# Generar embeddings en lotes\n",
    "embeddings = generate_embeddings_batch(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar desde archivo pickle\n",
    "with open('./data/processed/embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexando y almacenando en ChromaDB...\n",
      "Se han indexado 72405 tweets en la base de datos vectorial.\n"
     ]
    }
   ],
   "source": [
    "# 3. Indexar y almacenar en una base de datos vectorial\n",
    "print(\"Indexando y almacenando en ChromaDB...\")\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./data/processed/chroma_db\")\n",
    "\n",
    "collection = client.create_collection(name=\"climate_tweets\")\n",
    "\n",
    "# Dividimos los datos en lotes para evitar problemas de memoria\n",
    "batch_size = 1000\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    batch_embeddings = embeddings[i:i+batch_size]\n",
    "    batch_ids = ids[i:i+batch_size]\n",
    "    collection.add(\n",
    "        embeddings=batch_embeddings,\n",
    "        documents=batch_texts,\n",
    "        ids=batch_ids\n",
    "    )\n",
    "\n",
    "print(f\"Se han indexado {len(texts)} tweets en la base de datos vectorial.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(id=5e0f7022-4dde-41c9-ab53-dc03af38ac20, name=climate_tweets)\n"
     ]
    }
   ],
   "source": [
    "collection = client.get_collection(name=\"climate_tweets\")\n",
    "print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realizando una consulta de ejemplo...\n",
      "Procesados 0/1 textos\n",
      "\n",
      "Resultados de la consulta:\n",
      "1. ID: 4995\n",
      "   Text: jad daleycuenta_usuario regional ecosystem impact fr climatechange incl longer growing season snow rain altered soil moisture potl numero summer drought extreme event specie range shift invasive plant forest pest amp disease cuenta_usuario forestsaretheanswer\n",
      "   Distance: 35.33061218261719\n",
      "\n",
      "2. ID: 41153\n",
      "   Text: soil crucial player climatechange mitigation agricultural resilience read new study lowcost reliable system measure soil organic carbon eventually increase link_url cuenta_usuario cuenta_usuario cuenta_usuario cuenta_usuario\n",
      "   Distance: 36.292667388916016\n",
      "\n",
      "3. ID: 8283\n",
      "   Text: health ecosystem specie depend deteriorating rapidly ever ipbes 7cuenta_usuario globalassessment biodiversity ecosystem specie climatechange environment cuenta_usuario cuenta_usuario cuenta_usuario link_url\n",
      "   Distance: 36.65413284301758\n",
      "\n",
      "4. ID: 70377\n",
      "   Text: health ecosystem specie depend deteriorating rapidly ever ipbes 7cuenta_usuario globalassessment biodiversity ecosystem specie climatechange environment cuenta_usuario cuenta_usuario cuenta_usuario link_url\n",
      "   Distance: 36.936431884765625\n",
      "\n",
      "5. ID: 50892\n",
      "   Text: cuenta_usuario nous parle de limportance davoir un engagement citoyen constructif pour le enjeux de lagriculture sur le années à venir en prenant en compte le réchauffement climatique thank environment climatechange agriculture invivo anio_post_acuerdo_paris\n",
      "   Distance: 37.18337631225586\n",
      "\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# 4. Demostración de consulta\n",
    "print(\"\\nRealizando una consulta de ejemplo...\")\n",
    "query_text = [\n",
    "    \"Impact of climate change on biodiversity\", # 0\n",
    "    \"Urbanization's impact on wildlife habitats\", # 1\n",
    "    \"Ocean acidification and its consequences on marine life\", # 2\n",
    "    \"Global warming and the melting of polar ice caps\", # 3\n",
    "    \"Economic costs of climate change in coastal regions\", # 4\n",
    "    \"Impact of agriculture on freshwater ecosystems\", # 5\n",
    "    \"Relationship between carbon emissions and global temperature rise\", # 6\n",
    "    \"Conservation strategies for endangered species in changing climates\" # 7\n",
    "]\n",
    "\n",
    "# Generar embedding para la consulta\n",
    "query_embedding = generate_embeddings_batch([query_text[5]])\n",
    "\n",
    "# Realizar la consulta\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "print(\"\\nResultados de la consulta:\")\n",
    "for i, (id, text, distance) in enumerate(zip(results['ids'][0], results['documents'][0], results['distances'][0])):\n",
    "    print(f\"{i+1}. ID: {id}\")\n",
    "    print(f\"   Text: {text}\")\n",
    "    print(f\"   Distance: {distance}\\n\")\n",
    "\n",
    "print(\"Proceso completado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
